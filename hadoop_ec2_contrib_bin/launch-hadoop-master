#!/usr/bin/env bash

# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Launch an EC2 Hadoop master.

if [ -z $1 ]; then
  echo "Cluster name required!"
  exit -1
fi

CLUSTER=$1

# Import variables
bin=`dirname "$0"`
bin=`cd "$bin"; pwd`
#echo "bin directory is" "$bin"
. "$bin"/hadoop-ec2-env.sh

if [ -z $AWS_ACCOUNT_ID ]; then
  echo "Please set AWS_ACCOUNT_ID in $bin/hadoop-ec2-env.sh."
  exit -1
fi

if [ -z $AMI_IMAGE ]; then
  echo "Please set AMI_IMAGE in $bin/hadoop-ec2-env.sh."
  exit -1
fi

echo "Testing for existing master in group: $CLUSTER"
MASTER_EC2_HOST=`ec2-describe-instances | awk '"RESERVATION" == $1 && "'$CLUSTER_MASTER'" == $4, "RESERVATION" == $1 && "'$CLUSTER_MASTER'" != $4'`

MASTER_EC2_HOST=`echo "$MASTER_EC2_HOST" | awk '"INSTANCE" == $1 && "running" == $6 {print $4}'`

if [ ! -z "$MASTER_EC2_HOST" ]; then
  echo "Master already running on: $MASTER_EC2_HOST"
  MASTER_HOST=`ec2-describe-instances $INSTANCE | grep INSTANCE | grep running | grep $MASTER_EC2_HOST | awk '{print $5}'`
  echo $MASTER_HOST > $MASTER_PRIVATE_IP_PATH
  echo $MASTER_EC2_HOST > $MASTER_IP_PATH
  exit 0
fi

ec2-describe-group | egrep "[[:space:]]$CLUSTER_MASTER[[:space:]]" > /dev/null
if [ ! $? -eq 0 ]; then
  echo "Creating group $CLUSTER_MASTER"
  ec2-add-group $CLUSTER_MASTER -d "Group for Hadoop Master."
  ec2-authorize $CLUSTER_MASTER -o $CLUSTER_MASTER -u $AWS_ACCOUNT_ID
  ec2-authorize $CLUSTER_MASTER -p 22    # ssh

  if [ $ENABLE_WEB_PORTS == "true" ]; then
    ec2-authorize $CLUSTER_MASTER -p 50030 # JobTracker web interface
    ec2-authorize $CLUSTER_MASTER -p 50060 # TaskTracker web interface
    ec2-authorize $CLUSTER_MASTER -p 50070 # NameNode web interface
    ec2-authorize $CLUSTER_MASTER -p 50075 # DataNode web interface
    ec2-authorize $CLUSTER_MASTER -p 50001 # hdfs 
    ec2-authorize $CLUSTER_MASTER -p 50002 # mapred
    ec2-authorize $CLUSTER_MASTER -p 50010 # hdfs datanode
    ec2-authorize $CLUSTER_MASTER -p 8080 #spark master web
    ec2-authorize $CLUSTER_MASTER -p 4040 #spark master web
    ec2-authorize $CLUSTER_MASTER -p 8081 #spark worker web
    ec2-authorize $CLUSTER_MASTER -p 7077 #spark worker web

  fi
fi

ec2-describe-group | egrep "[[:space:]]$CLUSTER[[:space:]]" > /dev/null
if [ ! $? -eq 0 ]; then
  echo "Creating group $CLUSTER"
  ec2-add-group $CLUSTER -d "Group for Hadoop Slaves."
  ec2-authorize $CLUSTER -o $CLUSTER -u $AWS_ACCOUNT_ID
  ec2-authorize $CLUSTER -p 22    # ssh

  if [ $ENABLE_WEB_PORTS == "true" ]; then
    ec2-authorize $CLUSTER -p 50030 # JobTracker web interface
    ec2-authorize $CLUSTER -p 50060 # TaskTracker web interface
    ec2-authorize $CLUSTER -p 50070 # NameNode web interface
    ec2-authorize $CLUSTER -p 50075 # DataNode web interface
    ec2-authorize $CLUSTER -p 50001 # hdfs 
    ec2-authorize $CLUSTER -p 50002 # mapred
    ec2-authorize $CLUSTER -p 50010 # hdfs datanode
    ec2-authorize $CLUSTER -p 8080 #spark master web
    ec2-authorize $CLUSTER -p 8081 #spark worker web
    ec2-authorize $CLUSTER -p 7077 #spark worker web

  fi

  ec2-authorize $CLUSTER_MASTER -o $CLUSTER -u $AWS_ACCOUNT_ID
  ec2-authorize $CLUSTER -o $CLUSTER_MASTER -u $AWS_ACCOUNT_ID
fi

# Start a master
echo "Starting master with AMI $AMI_IMAGE and INSTANCE_TYPE ${INSTANCE_TYPE}"

echo "Going to run command: ec2-run-instances $AMI_IMAGE -n 1 -g $CLUSTER_MASTER -k $KEY_NAME -t $INSTANCE_TYPE $KERNEL_ARG"

# NOTE: we removed the "-f $bin/$USER_DATA_FILE" part in the command below. We now explicitly scp 
#   this script to the Hadoop nodes, and run the script
#INSTANCE=`ec2-run-instances $AMI_IMAGE -n 1 -g $CLUSTER_MASTER -k $KEY_NAME -f "$bin"/$USER_DATA_FILE -t $INSTANCE_TYPE $KERNEL_ARG | grep INSTANCE | awk '{print $2}'`
INSTANCE=`ec2-run-instances $AMI_IMAGE -n 1 -g $CLUSTER_MASTER -k $KEY_NAME -t $INSTANCE_TYPE $KERNEL_ARG | grep INSTANCE | awk '{print $2}'`

echo "Waiting for instance $INSTANCE to start"
while true; do
  printf "."
  # get private dns
  MASTER_HOST=`ec2-describe-instances $INSTANCE | grep running | awk '{print $5}'`
  if [[ ! -z $MASTER_HOST ]]; then
    echo "Started as $MASTER_HOST"
    break;
  fi
  sleep 1
done

MASTER_EC2_HOST=`ec2-describe-instances $INSTANCE | grep INSTANCE | grep running | grep $MASTER_HOST | awk '{print $4}'`
echo $MASTER_HOST > $MASTER_PRIVATE_IP_PATH
echo $MASTER_EC2_HOST > $MASTER_IP_PATH
MASTER_EC2_ZONE=`ec2-describe-instances $INSTANCE | grep INSTANCE | grep running | grep $MASTER_HOST | awk '{print $11}'`
echo $MASTER_EC2_ZONE > $MASTER_ZONE_PATH

echo "HADOOP_MASTER_NODE is ${MASTER_EC2_HOST}"

while true; do
  REPLY=`ssh $SSH_OPTS "ec2-user@$MASTER_EC2_HOST" 'echo "hello"'`
  if [[ ! -z $REPLY ]]; then
   break;
  fi
  sleep 5
done




echo "Copying private key to master"
scp $SSH_OPTS $PRIVATE_KEY_PATH "ec2-user@$MASTER_EC2_HOST:/home/ec2-user/.ssh/id_rsa"
ssh $SSH_OPTS "ec2-user@$MASTER_EC2_HOST" "chmod 600 /home/ec2-user/.ssh/id_rsa"

# NOTE: we removed the "-f $bin/$USER_DATA_FILE" part from the ec2-run-instances command above. We now explicitly scp 
#   this script to the Hadoop nodes, and run the script
scp $SSH_OPTS "${bin}/${USER_DATA_FILE}" "ec2-user@$MASTER_EC2_HOST:/home/ec2-user/ec2_hadoop_master_init.sh"
ssh $SSH_OPTS "ec2-user@$MASTER_EC2_HOST" "sh /home/ec2-user/ec2_hadoop_master_init.sh"

MASTER_IP=`dig +short $MASTER_EC2_HOST`
echo "HADOOP_MASTER_NODE is $MASTER_EC2_HOST, ip is $MASTER_IP, zone is $MASTER_EC2_ZONE."
