# Instructions
# 1. Copy this file and remove the .template extension
#    >$ cp local_ec2_settings.sh.template local_ec2_settings.sh
# 2. Modify the settings in local_ec2_settings.sh as needed to launch
#    the appropriate cluster with the correct credentials
# 3. Do NOT modify hadoop-ec2-env.sh or local_ec2_settings.sh.template
# #############################

# Name of the EC2 keypair file
KEY_NAME="${EC2_KEYPAIR_NAME}"

# The full path to the EC2 keypair file
PRIVATE_KEY_PATH=`echo "$EC2_KEYDIR"/"$KEY_NAME"`

# Supported types: m1.small, m1.large, m1.xlarge, c1.medium, c1.xlarge, cc1.4xlarge
INSTANCE_TYPE="m1.small"

# Supported versions: less than 0.19.0, 0.20.2, 0.20.203.0
HADOOP_VERSION="0.20.2"

#HADOOP OR SPARK?
FRAMEWORK_TYPE="HADOOP"

# The AMI image to use with HADOOP_VERSION 0.20.2 or 0.20.203.0
# If INSTANCE_TYPE is "m1.small" or "c1.medium", AMI_IMAGE_32 is used.
# Otherwise, AMI_IMAGE_64 is used.

#    AMI ami-5729c03e: Ned created with Hadoop 0.20.2 (32 bit)
#    AMI ami-2817ff41: Shivnath created with Hadoop 0.20.2, Ganglia (32 bit)
#    AMI ami-73b97b1a: Fei created with Hadoop 0.20.203.0, Pig 0.9.0, Ant (32 bit)
#    AMI ami-74832e1d: Harold created with Hadoop 0.20.203.0, Pig 0.9.0, Ant, Ganglia (32-bit)
AMI_IMAGE_32="ami-2817ff41"

#    AMI ami-a0ee12c9: Fei created with Hadoop 0.20.2, Ganglia (64 bit)
#    AMI ami-e7bf7d8e: Fei created with Hadoop 0.20.203.0, Pig 0.9.0, Ant (64 bit)
#    AMI ami-58802d31: Harold created with Hadoop 0.20.203.0, Pig 0.9.0, Ant, Ganglia (64 bit)
#    AMI ami-8f188fe6: Harold created with Hadoop 0.20.203.0, Pig 0.9.0, ant, ganglia (64-bit), Spark 0.6.1, Shark 0.2.1, mysql
AMI_IMAGE_64="ami-a0ee12c9"
