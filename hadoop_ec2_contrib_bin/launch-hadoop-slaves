#!/usr/bin/env bash

# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Launch an EC2 Hadoop slaves.

if [ -z $1 ]; then
  echo "Cluster name required!"
  exit -1
fi

if [ -z $2 ]; then
  echo "Must specify the number of slaves to start."
  exit -1
fi

CLUSTER=$1
NO_INSTANCES=$2

# Import variables
bin=`dirname "$0"`
bin=`cd "$bin"; pwd`
. "$bin"/hadoop-ec2-env.sh

if [ ! -f $MASTER_IP_PATH ]; then
  echo "Must start Cluster Master first!"
  exit -1
fi

# Finding Hadoop image
if [ $HADOOP_VERSION == "0.20.2" ]; then
   # This is an image that Ned created: 
   #    https://wiki.duke.edu/display/hadoop/List+of+Current+AMI+Images
   AMI_IMAGE="ami-5729c03e"
else 
   # This part will only work for $HADOOP_VERSION being 0.19.0 or less 
   AMI_IMAGE=`ec2-describe-images -a | grep $S3_BUCKET | grep $HADOOP_VERSION | grep $ARCH | grep available | awk '{print $2}'`   
fi

MASTER_HOST=`cat $MASTER_PRIVATE_IP_PATH`
MASTER_EC2_HOST=`cat $MASTER_IP_PATH`
MASTER_ZONE=`cat $MASTER_ZONE_PATH`

# Substituting master hostname
sed -e "s|%MASTER_HOST%|$MASTER_HOST|" "$bin"/$USER_DATA_FILE > "$bin"/${USER_DATA_FILE}.slave

# Start slaves
echo "Adding $2 node(s) to cluster group $CLUSTER with AMI $AMI_IMAGE"
#ec2-run-instances $AMI_IMAGE -n "$NO_INSTANCES" -g "$CLUSTER" -k "$KEY_NAME" -f "$bin"/$USER_DATA_FILE.slave -t "$INSTANCE_TYPE" -z "$MASTER_ZONE" $KERNEL_ARG | grep INSTANCE | awk '{print $2}' > "${AWS_HADOOP_HARNESS_HOME}"/SLAVE_INSTANCE_IDS.txt
ec2-run-instances $AMI_IMAGE -n "$NO_INSTANCES" -g "$CLUSTER" -k "$KEY_NAME" -t "$INSTANCE_TYPE" -z "$MASTER_ZONE" $KERNEL_ARG | grep INSTANCE | awk '{print $2}' > "${AWS_HADOOP_HARNESS_HOME}"/SLAVE_INSTANCE_IDS.txt
cat "${AWS_HADOOP_HARNESS_HOME}"/SLAVE_INSTANCE_IDS.txt

echo "Waiting for the $2 instances to start"

# we will capture the private IPs of the slaves in "${AWS_HADOOP_HARNESS_HOME}"/SLAVE_NAMES.txt
echo -n >"${AWS_HADOOP_HARNESS_HOME}"/SLAVE_NAMES.txt

for INSTANCE in $(<"${AWS_HADOOP_HARNESS_HOME}"/SLAVE_INSTANCE_IDS.txt); do
   while true; do
     # get private dns for the instance
     INSTANCE_HOST=`ec2-describe-instances $INSTANCE | grep running | awk '{print $5}'`
     if [ ! -z $INSTANCE_HOST ]; then
       echo "$INSTANCE_HOST" >> "${AWS_HADOOP_HARNESS_HOME}"/SLAVE_NAMES.txt
       echo "Instance $INSTANCE has been assigned private IP $INSTANCE_HOST"
       break;
     fi
     sleep 1
   done
done

#cat "${AWS_HADOOP_HARNESS_HOME}"/SLAVE_NAMES.txt

scp $SSH_OPTS "${bin}/${USER_DATA_FILE}.slave" "root@$MASTER_EC2_HOST:"
scp $SSH_OPTS "${AWS_HADOOP_HARNESS_HOME}"/SLAVE_NAMES.txt "root@$MASTER_EC2_HOST:"
#scp $SSH_OPTS "${bin}/start_hadoop_on_slaves.sh" "root@$MASTER_EC2_HOST:"
#ssh $SSH_OPTS "root@$MASTER_EC2_HOST" "/root/start_hadoop_on_slaves.sh"

rm "$bin"/${USER_DATA_FILE}.slave
