Description / Purpose
---------------------
The scripts in these directories can be used to perform various operations
in a hadoop cluster.

-----------------------------------------------------------------------------
-----------------------------------------------------------------------------
Script: copy_files_to_slaves
----------------------------
This script can be used to copy files to all the slaves.

Usage:
 perl copy_files_to_slaves.pl slaves_file local_file slave_dir
  
 where:
   slaves_file = File containing a list of slave machines
   local_file  = File or directory to copy to the slave machines
   slave_dir   = Directory to copy the files to in the host machines

Assumptions/Requirements:
 The slaves directory exists in the slave nodes

Example:
 perl copy_files_to_slaves.pl /root/SLAVE_NAMES.txt file.txt /root/target


-----------------------------------------------------------------------------
-----------------------------------------------------------------------------
Script: run_cmd_on_slaves.pl
----------------------------
This script can be used to execute the same command to all the slaves.

Usage:
 perl run_cmd_on_slaves.pl slaves_file wait ('cmd'|"cmd")
  
 where:
   slaves_file = File containing a list of slave machines
   wait        = true or false, whether to wait for each cmd to finish or not
   cmd         = The cmd to execute (surrounded by single or double quotes)

Assumptions/Requirements:
 The enviromental variable $HADOOP_HOME is defined in the master node

Example:
 perl run_cmd_on_slaves.pl /root/SLAVE_NAMES.txt "ls -l /root"


-----------------------------------------------------------------------------
-----------------------------------------------------------------------------
Script: unify_exper_logs.pl
----------------------------
This script can be used to copy/move a set of logs from the experiment
directories (EXPT-xxxx) to a single unified directory. For example,
this script can copy all the history files from each experiment to
a single history directory

Usage:
 perl unify_exper_logs.pl target exper_dir out_dir [mv]
 
 where:
   target    = is one of history, profiles, userlogs, or transfers
   exper_dir = Base directory for the harness experiments
   out_dir   = The output directory
   mv        = Optional flag to move the files instead of copying

Assumptions/Requirements:
 The exper_dir is a valid directory with experiments and the file
 RANDOMIZED_EXPERIMENT_LIST.txt exists.

Example:
 perl unify_exper_logs.pl history BASE OUT
 Note: The OUT/history directory will be created and it will contain all
       the files contained in the BASE/EXPT-****/history directories.


-----------------------------------------------------------------------------
-----------------------------------------------------------------------------
Script: merge_files.pl
----------------------------
This script can be used to merge files together horizontally, that is
the rows from each input file are appended together (separated by a tab)
to form the output file.

Usage:
 perl merge_files.pl output input_1 input_2 ... input_n
 
 where:
   output  = The output file (must not exist)
   input_i = The input files to merge (must have same number of rows)

Assumptions/Requirements:
 The output file must not exist.
 The input files must exist and have the same number of rows.

Example:
 perl merge_files.pl output input_1 input_2


-----------------------------------------------------------------------------
-----------------------------------------------------------------------------
Script: gen_profiles.pl
----------------------------
This script can be used to generate the XML profiles of all the jobs
for an experiment.

Usage:
  perl gen_profiles.pl profile_jar exper_dir out_dir
  
  where:
    profile_jar = The profile jar
    exper_dir = Base directory for the harness experiments
    out_dir   = The output directory

Assumptions/Requirements:
  The exper_dir is a valid directory with experiments and contains:
    (a) a file called 'HADOOP_JOB_IDS.txt'
    (b) a directory called 'history' with the conf/history files
    (c) a directory called 'profiles' with the profile files

Example:
  perl gen_profiles.pl /root/starfish-profiles.jar BASE OUT
  Note: The OUT directory will be created and it will contain
        files of the form profile_job_id.xml


-----------------------------------------------------------------------------
-----------------------------------------------------------------------------
Script: predict_time.pl
----------------------------
This script can be used to test the What-if Engine for all the jobs
in a harness experiment.

Usage:
  perl predict_time.pl whatif_jar exper_dir profiles
  
  where:
    whatif_jar = The whatif jar
    exper_dir  = Base directory for the harness experiments
    profiles   = The directory with the job profiles or a single profile file

Assumptions/Requirements:
  The exper_dir is a valid directory with experiments and contains:
    (a) a file called 'HADOOP_JOB_IDS.txt'
    (b) a directory called 'results/history'

  The profiles_dir is a valid directory with the job profiles
  named either 'profile_job_EXPTID.xml' or 'profile_JOBID.xml',
  or a single job profile file.


-----------------------------------------------------------------------------
-----------------------------------------------------------------------------
Script: adjust_profiles.pl
----------------------------
This script can be used to generate the adjusted XML profiles of all the jobs
for two experiments. The first experiment run without compression and the
second run with compression.

Usage:
  perl adjust_profiles.pl profile_jar compr_no_dir compr_yes_dir out_dir
  
  where:
    profile_jar   = The profile jar
    compr_no_dir  = Base directory for experiments without compression
    compr_yes_dir = Base directory for experiments with compression
    out_dir       = The output directory

Assumptions/Requirements:
  The compr_*_dir are valid directories with experiments and:
    (a) each contains a file called 'HADOOP_JOB_IDS.txt'
    (b) each contains a directory called results/job_profiles
    (c) have the same number of experiments with one-to-one correspondance





